{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a352d2-2239-445c-a13c-fe2bbe81c77b",
   "metadata": {},
   "source": [
    "## Cilia segmentation\n",
    "The purpose of this notebook is to segment cilia by training the APOC pixel classifier. Both a semantic segmentation to segment the cilia channel and binarise, and object segmentation to classify the cilia intro three types are used to complete the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af8dcc-5d16-4230-91ec-5a5dfe97e316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apoc import PixelClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "import numpy as np\n",
    "from readlif.reader import LifFile\n",
    "from skimage.io import imsave\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.morphology import (\n",
    "    disk,\n",
    "    binary_opening,\n",
    "    binary_closing,\n",
    "    binary_dilation,\n",
    "    binary_erosion,\n",
    "    remove_small_objects,\n",
    "    label,\n",
    "    remove_small_holes,\n",
    ")\n",
    "from skimage.measure import label\n",
    "from tifffile import TiffFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39663a06-2ae7-4397-894d-dff0f4428324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lifloader(path, index):\n",
    "    \"\"\"\n",
    "    This function loads the .lif file experiment by indicating the path where the file is found and the image index (position in the folder).\n",
    "    TTiffFileunction reconstructs the image by using its channels and z stack. It returns an ndarray.\n",
    "    Parameters:\n",
    "    path: path\n",
    "        Path where the .lif file is found.\n",
    "    index: integer\n",
    "        Indicates the image to be later opened from the experiment file (starting from 0).\n",
    "    \"\"\"\n",
    "    file = LifFile(path)\n",
    "    img = file.get_image(index)\n",
    "\n",
    "    # The Z-stack images are piled up in their corresponding channels and the image is converted to an array.\n",
    "    all_img = []\n",
    "    for c in range(img.channels):\n",
    "        this_z_stack = []\n",
    "        for z in range(img.nz):\n",
    "            this_z_stack.append(np.array(img.get_frame(z, 0, c, 0)))\n",
    "        this_z_stack = rescale_intensity(np.asarray(this_z_stack))\n",
    "        all_img.append(this_z_stack)\n",
    "    all_img_array = np.array(all_img)\n",
    "\n",
    "    # The image format is reshaped by changing the order of variables. This is done so Napari is able to read the image correctly.\n",
    "    all_img_reshaped = np.reshape(\n",
    "        all_img_array, (img.nz, img.channels, img.dims[0], img.dims[1])\n",
    "    )\n",
    "    all_img_reshaped2 = all_img_reshaped.transpose(1, 0, 2, 3)\n",
    "    plt.imshow(all_img_reshaped2[0, 30, :, :])\n",
    "\n",
    "    return all_img_reshaped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a18d6-ec60-46cd-819c-a46acad2f10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = lifloader(\n",
    "    \"D:/estela/data/microscopy/leica_stellaris/20231025_p1_cd13_opn_arl13b/20231025_p1_cd13_opn_arl13b.lif\",\n",
    "    5,\n",
    ")\n",
    "cilia_channel = img[1]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(cilia_channel, scale=(0.3, 0.144, 0.144))\n",
    "napari.utils.nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be8fc6-aac4-469b-ab4b-cf5bad3c5721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for_training_file = TiffFile(\n",
    "    \"D:/estela/results/20240304/cilia_for_training.tif\"\n",
    ")\n",
    "for_training = for_training_file.asarray()\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(cilia_channel, scale=(0.3, 0.144, 0.144))\n",
    "viewer.add_labels(for_training, opacity=1)\n",
    "napari.utils.nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff60eb-46ad-4790-9099-fa8fefa9b0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmenter = PixelClassifier(\n",
    "    opencl_filename=\"D:/estela/results/20240304/PixelClassifier_2.cl\"\n",
    ")\n",
    "prediction = segmenter.predict(cilia_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42e8b4-f178-4ed0-a361-b1423b0fc891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(cilia_channel)  # , scale = (0.3, 0.144, 0.144))\n",
    "viewer.add_labels(prediction.get(), opacity=0.2)\n",
    "# viewer.add_labels(for_training, opacity=1)\n",
    "napari.utils.nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4b43b-8d4f-414a-bbf6-afb1666d5835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eroded_prediction = binary_erosion((np.array(prediction) > 1))\n",
    "polished_prediction = remove_small_objects(eroded_prediction, min_size=200)\n",
    "dilated_prediction = binary_dilation(polished_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fa13d-7b13-42c9-a00c-b5b9a2ce95a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(cilia_channel)  # , scale = (0.3, 0.144, 0.144))\n",
    "viewer.add_labels(prediction, opacity=0.2)\n",
    "viewer.add_labels(eroded_prediction, opacity=0.2)\n",
    "viewer.add_labels(polished_prediction, opacity=0.2)\n",
    "viewer.add_labels(dilated_prediction, opacity=0.2)\n",
    "# viewer.add_labels(for_training, opacity=1)\n",
    "napari.utils.nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7417163-ba3e-4fc1-b00e-5b7eff911ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelled_prediction = label(dilated_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98367d2-1361-4216-8a74-e3b83141d083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(cilia_channel)  # , scale = (0.3, 0.144, 0.144))\n",
    "viewer.add_labels(dilated_prediction, opacity=0.2)\n",
    "viewer.add_labels(labelled_prediction)\n",
    "# viewer.add_labels(for_training, opacity=1)\n",
    "napari.utils.nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5496f-74ee-4de9-8f14-3d846f7389a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imsave(\"labelled_prediction.tif\", labelled_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
